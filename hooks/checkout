#!/usr/bin/env bash

set -euo pipefail

if [[ -n "${BUILDKITE_PLUGIN_GITHUB_FETCH_BASH_PREFIX:-}" ]]; then
  eval "${BUILDKITE_PLUGIN_GITHUB_FETCH_BASH_PREFIX}"
fi

# Method used to initialise the repo
# 0: unknown
# 1: clone
# 2: S3 copy
# 3: clean existing repo
INITILISATION_METHOD=0

# The maximum amount of time (in seconds) that a remote Git operation (fetch, pull, push) can take.
# If not specified by the user, no timeout will be applied to Git remote operations.
GIT_REMOTE_TIMEOUT="${BUILDKITE_PLUGIN_GITHUB_FETCH_GIT_REMOTE_TIMEOUT:-0}"

# Here is the exit code to be returned by this script when a remote Git operations times out.
# Having a specific exit code for these scenarions allows to configure Buildkite pipelines to retry
# the whole step without hiding underlying issues.
# See: https://buildkite.com/docs/pipelines/command-step#automatic-retry-attributes
#
# If not specified by the user, it defaults to 110 which is the standard exit code for connection timeout.
GIT_REMOTE_TIMEOUT_EXIT_CODE="${BUILDKITE_PLUGIN_GITHUB_FETCH_GIT_REMOTE_TIMEOUT_EXIT_CODE:-110}"

# Set to `true` forces a fresh clone from the remote to initialize the local copy for the first time
# on the agent.
#
# Otherwise it will re-use a cached copy from S3 for the first time or re-use the local repository.
BUILDKITE_CLEAN_CHECKOUT="${BUILDKITE_CLEAN_CHECKOUT:-false}"

PROXY_URL_SSM_PARAM="${GH_CONTROL_USER_ENV_GITHUB_CHECKOUT_PLUGIN_PROXY_URL_SSM_PARAM:-${BUILDKITE_PLUGIN_GITHUB_FETCH_PROXY_URL_SSM_PARAM:-/github/git-proxy/url}}"
PROXY_ROLLOUT_SSM_PARAM="${GH_CONTROL_USER_ENV_GITHUB_CHECKOUT_PLUGIN_PROXY_ROLLOUT_SSM_PARAM:-${BUILDKITE_PLUGIN_GITHUB_FETCH_PROXY_ROLLOUT_SSM_PARAM:-/github/git-proxy/rollout}}"


# Invoke mktemp in a way which works on macOS and GNU/Linux
git_log=$(mktemp "${TMPDIR:-/tmp/}githublog.XXXXXXXXXX")

PLUGIN_DIR="$(cd "$( dirname "${BASH_SOURCE[0]}" )/.." && pwd)"

OUTFILE=$(mktemp)

# Prints an info line to stdout.
log_info() {
  echo "$(date '+[%Y-%m-%d %H:%M:%S]') INFO: $*"
}

log_and_run() {
  echo "COMMAND:" "$@" >> "${git_log}"
  "$@" &>> "${git_log}"
}

# Checks if an env var is set
# Arguments:
# $1: var name
check_set() {
  local name="$1"
  if [[ -z "${!name:-}" ]]; then
    echo "ERROR: ${name} not set"
    exit 1
  fi
}

# Checks for failed exit codes returned by a timeout command.
# If the underlying command fails due to timeout, this function stops the current execution returning either the
# TIMEOUT exit code (124) or the override value provided by the caller.
# In any other non-timeout failure scenarios, the current execution is stopped but the underlying command's exit
# code is returned unmodified.
# Arguments:
#   $1: The exit code returned by the timeout command.
#   $2: The exit code to be returned when the underlying command times out.
check_timeout_exit_code() {
  local exit_code="$1"
  local timeout_exit_code_override="${2:-}"
  if [[ "${exit_code}" -eq 124 && -n "${timeout_exit_code_override}" ]]; then
    return "${timeout_exit_code_override}"
  elif [[ "${exit_code}" -ne 0 ]]; then
    return "${exit_code}"
  fi
}

exit_handler() {
  if [[ -f "${git_log}" ]]; then
    mv "${git_log}" "${git_log}.log"
    buildkite-agent artifact upload "${git_log}.log"
    rm -rf "${git_log}.log"
  else
    log_info "Git log file '${git_log}' not found."
  fi
  rm "${OUTFILE}"
}

print_repo_dir() {
  grep -Eo '([a-zA-Z0-9-]+\/[a-zA-Z0-9-]+)\.git' <<< "${BUILDKITE_REPO}" \
      | tr '[:upper:]' '[:lower:]' \
      | sed -e 's/.git$//' -e 's/\//__/g'
}

copy_checkout_from_s3() {
  local repo_dir=$(print_repo_dir)
  local s3_url="${1}/${repo_dir}"
  local checkout

  log_info "Getting checkout from S3"

  clean_checkout_dir

  # Find the most recent checkout in S3.
  checkout=$(aws s3 ls "${s3_url}/" \
      | (sort -r -k 4 || true) \
      | head -n1 \
      | awk '{print $4}'
  )

  pushd .. >/dev/null

  echo "copying checkout ${s3_url}/${checkout}"
  # Use aria2c download utility if available in the supplied AMI. It parallelize the download which
  # speeds up the fetch considerably. aria2c can be installed with `sudo apt-get install aria2`.
  # Benchmarking shows the repo can be downloaded a 50% reduction in download time.
  if command -v aria2c &> /dev/null; then
    local signed_url
    signed_url="$(aws s3 presign --region us-east-1 "${s3_url}/${checkout}")"
    aria2c --max-connection-per-server=16 --split=16 "${signed_url}" --out="${checkout}"
  else
    aws s3 cp "${s3_url}/${checkout}" "${PWD}/${checkout}"
  fi

  local -a decompress_options
  if [[ "$(basename "${checkout}" ".zst")" != "${checkout}" ]]; then
    # Decompress using zstd
    decompress_options=("-I" "zstd")
  else
    # Auto-detect decompression options
    decompress_options=()
  fi

  tar "${decompress_options[@]}" -xf "${PWD}/${checkout}"
  rm "${PWD}/${checkout}"
  popd >/dev/null

  log_info "Copying from S3 done"
}

# prints the major version of the aws cli running
print_aws_version() {
    local version
    version=$(aws --version 2>&1)
    [[ "${version}" =~ ^aws-cli\/([0-9])\.[0-9]+.[0-9]+ ]]
    echo "${BASH_REMATCH[1]}"
}

print_ssm_param(){
  local ssm_param="${1}"
  local aws_version
  aws_version=$(print_aws_version)
  local -a params
  if [[ "${aws_version}" == "2" ]]; then
    params=(--cli-binary-format raw-in-base64-out)
  else
    params=()
  fi
  local lambda_output
  lambda_output=$(aws lambda invoke \
      --region us-east-1 \
      --function-name ssm-cache \
      --payload "{\"ssm_param\": \"${ssm_param}\"}" \
      "${params[@]}" "${OUTFILE}")
  if [[ $(jq -r 'has("FunctionError")' <<< "${lambda_output}") == "false" ]]; then
    # if no error in response, print message
    jq -r '.body | fromjson | .message' < "${OUTFILE}"
  fi
}

print_proxy_url() {
  local proxy_url
  proxy_url=$(print_ssm_param "${PROXY_URL_SSM_PARAM}")
  echo "proxy url param is ${proxy_url}" 1>&2
  if [[ -n "${proxy_url:-}" ]]; then
    local repo_dir
    repo_dir=$(print_repo_dir)
    local proxy_rollout_param="${PROXY_ROLLOUT_SSM_PARAM}/${repo_dir}"

    local rollout
    rollout=$(print_ssm_param "${proxy_rollout_param}")
    echo "proxy rollout param is ${rollout}" 1>&2
    if [[ -n "${rollout:-}" && $((1 + $RANDOM % 100)) -le "${rollout}" ]]; then
      echo "${proxy_url}"
    fi
  fi
}

unset_proxy() {
  if git config --get-regexp 'http.*.proxy' > /dev/null; then
    for name in $(git config --name-only --get-regexp 'http.*.proxy'); do
      echo "unset ${name}"
      git config --unset "${name}"
    done
  fi
  if git config --get remote.origin.pushurl > /dev/null; then
    echo "unset remote.origin.pushurl"
    git config --unset remote.origin.pushurl
  fi
}

checkout() {
  log_info "Starting checkout"

  local exit_code
  exit_code=0

  local proxy_url
  proxy_url=$(print_proxy_url)
  if [[ -n "${proxy_url:-}" ]]; then
    if [[ "${BUILDKITE_REPO}" =~ ^https://.* ]]; then
      # BUILDKITE_REPO is in https protocol
      log_info "Using proxy: ${proxy_url}"
      git config http."http://github.com/${BUILDKITE_REPO#*@github.com/}".proxy "${proxy_url}"
      # convert https to http for pull
      git config remote.origin.url "http://${BUILDKITE_REPO#https://}"
      git config remote.origin.pushurl "${BUILDKITE_REPO}"
    elif [[ "${BUILDKITE_REPO}" =~ ^http://.* ]]; then
      # BUILDKITE_REPO is in http protocol
      log_info "Using proxy: ${proxy_url}"
      git config http."http://github.com/${BUILDKITE_REPO#*@github.com/}".proxy "${proxy_url}"
      git config remote.origin.url "${BUILDKITE_REPO}"
      # convert http to https for push
      git config remote.origin.pushurl "https://${BUILDKITE_REPO#http://}"
    elif [[ "${proxy_url}" =~ ^https://.* ]]; then
      # BUILDKITE_REPO is in git protocol and proxy requires authentication
      # since we don't have the token, we can't use the proxy
      log_info "Not using proxy"
      unset_proxy
      git config remote.origin.url "${BUILDKITE_REPO}"
    else
      # BUILDKITE_REPO is in git protocol and proxy do not require authentication
      # therefore we can still use proxy without the token
      log_info "Using proxy: ${proxy_url}"
      git config http."http://github.com/${BUILDKITE_REPO#*@github.com:}".proxy "${proxy_url}"
      # convert git to http for pull
      git config remote.origin.url "http://github.com/${BUILDKITE_REPO#*@github.com:}"
      # keep the git url for push (existing behaviour)
      git config remote.origin.pushurl "${BUILDKITE_REPO}"
    fi
  else
    log_info "Not using proxy"
    unset_proxy
    git config remote.origin.url "${BUILDKITE_REPO}"
  fi

  git config protocol.version 2
  git reset --hard
  git clean -ffxdq

  # Check the current state to make sure we start from a clean working tree.
  # This does both "refresh the index and updating the cached stat information"
  # as per `man git-status` **BACKGROUND REFRESH**.
  git status

  git config remote.origin.fetch

  if [[ -z "${BUILDKITE_COMMIT:-}" || "${BUILDKITE_COMMIT}" == "HEAD" ]]; then
    log_info "Commit ID is not supplied. Fetch from HEAD."
    exit_code=0
    GIT_TRACE=1 GIT_CURL_VERBOSE=1 log_and_run "${PLUGIN_DIR}/bin/timeout" "${GIT_REMOTE_TIMEOUT}" git fetch -v --no-tags origin "${BUILDKITE_BRANCH}" || exit_code=$?
    check_timeout_exit_code "${exit_code}" "${GIT_REMOTE_TIMEOUT_EXIT_CODE}"
    if [[ "${exit_code}" -ne 0 ]]; then
      log_info "Git returned error code:${exit_code}"
      return "${exit_code}"
    fi
    GIT_TRACE=1 GIT_CURL_VERBOSE=1 log_and_run git checkout -f FETCH_HEAD || exit_code=$?
  elif git cat-file -e "${BUILDKITE_COMMIT}"; then
    log_info "Checkout BUILDKITE_COMMIT=${BUILDKITE_COMMIT}"
    GIT_TRACE=1 GIT_CURL_VERBOSE=1 log_and_run git checkout -f "${BUILDKITE_COMMIT}" || exit_code=$?
  else
    # full commit sha is required
    if [[ ! "${BUILDKITE_COMMIT}" =~ [0-9a-f]{40} ]]; then
      log_info "Commit SHA ${BUILDKITE_COMMIT} is not valid. Full SHA is required."
      exit 1
    fi

    log_info "Fetch BUILDKITE_COMMIT=${BUILDKITE_COMMIT}"
    exit_code=0
    GIT_TRACE=1 GIT_CURL_VERBOSE=1 log_and_run "${PLUGIN_DIR}/bin/timeout" "${GIT_REMOTE_TIMEOUT}" git fetch -v --no-tags origin "${BUILDKITE_COMMIT}" || exit_code=$?
    check_timeout_exit_code "${exit_code}" "${GIT_REMOTE_TIMEOUT_EXIT_CODE}" || exit_code=$?
    # If the commit isn't there the ref that was pointing to it might have
    # been force pushed in the meantime. Exit with ESTALE to signify the stale
    # branch reference in that case.
    if [[ "${exit_code}" -eq 128 ]]; then
      log_info "Commit SHA ${BUILDKITE_COMMIT} does not exists. The ref might have been force pushed."
      return 116
    # If checking out the commit fails, it might be because the commit isn't
    # being advertised. In that case fetch the branch instead.
    elif [[ "${exit_code}" -ne 0 ]]; then
      log_info "Fail to checkout commit:${BUILDKITE_COMMIT}. Checkout branch:${BUILDKITE_BRANCH} instead."
      exit_code=0
      GIT_TRACE=1 GIT_CURL_VERBOSE=1 log_and_run "${PLUGIN_DIR}/bin/timeout" "${GIT_REMOTE_TIMEOUT}" git fetch -v --no-tags origin "${BUILDKITE_BRANCH}" || exit_code=$?
      check_timeout_exit_code "${exit_code}" "${GIT_REMOTE_TIMEOUT_EXIT_CODE}" || exit_code=$?
      if [[ "${exit_code}" -ne 0 ]]; then
        log_info "Git returned error code:${exit_code}"
        return "${exit_code}"
      fi
    fi
    # If the commit doesn't exist the ref that was pointing to it might have
    # been force pushed in the meantime. Exit with ESTALE to signify the stale
    # branch reference in that case.
    exit_code=0
    GIT_TRACE=1 GIT_CURL_VERBOSE=1 log_and_run git checkout -f "${BUILDKITE_COMMIT}" || exit_code=$?
    if [[ "${exit_code}" -eq 128 ]]; then
      log_info "Commit SHA ${BUILDKITE_COMMIT} does not exists. The ref might have been force pushed."
      return 116
    elif [[ "${exit_code}" -ne 0 ]]; then
      log_info "Git returned unknown code:${exit_code}"
      return "${exit_code}"
    fi
  fi

  if [[ "${exit_code}" -eq 0 ]]; then
    log_info "Checkout done"
  fi

  return "${exit_code}"
}

clean_checkout_dir() {
  rm -rf "${BUILDKITE_BUILD_CHECKOUT_PATH}"
  mkdir -p "${BUILDKITE_BUILD_CHECKOUT_PATH}"
  cd "${BUILDKITE_BUILD_CHECKOUT_PATH}"
}

clone() {
  log_info "Cloning repo from github"
  local exit_code
  # The git clone operation needs an empty directory.
  clean_checkout_dir
  exit_code=0
  "${PLUGIN_DIR}/bin/timeout" "${GIT_REMOTE_TIMEOUT}" git clone "${CANVA_REPO}" . || exit_code=$?
  check_timeout_exit_code "${exit_code}" "${GIT_REMOTE_TIMEOUT_EXIT_CODE}"
  log_info "Cloning from github done"
}

initialize_local_repo() {
  # Force a fresh clone.
  if [[ "${BUILDKITE_CLEAN_CHECKOUT}" == "true" ]]; then
    clone
    INITILISATION_METHOD=1
  # If there is no local repository or the index is in a locked state.
  # When the lock file exists it's probably because a previous job was killed while checking out the
  # repo, in which case it might be corrupted.
  elif [[ "$(git rev-parse --is-inside-work-tree 2>/dev/null)" != "true" || -f ".git/index.lock" ]]; then
    if [[ -n "${BUILDKITE_PLUGIN_GITHUB_FETCH_S3_URL:-}" ]]; then
      copy_checkout_from_s3 "${BUILDKITE_PLUGIN_GITHUB_FETCH_S3_URL}"
      INITILISATION_METHOD=2
    else
      # When S3 was not configured, fallback to Git clone
      clone
      INITILISATION_METHOD=1
    fi
  else
    log_info "Using existing local repository"
    INITILISATION_METHOD=3
  fi
}

setup_git_lfs() {
  if [[ "${CANVA_REPO}" =~ .*github\.com.* ]]; then
    # Workaround for GitHub git-lfs API rate limit error:
    # https://github.com/git-lfs/git-lfs/issues/2133#issuecomment-292557138
    # Also setting both https and http URLs, so that if git-proxy requires http URL as remote it should still work.
    if [[ "${CANVA_REPO}" =~ ^https?://.* ]]; then
      git config "lfs.https://github.com/${CANVA_REPO#*@github.com/}/info/lfs.access" basic
      git config "lfs.http://github.com/${CANVA_REPO#*@github.com/}/info/lfs.access" basic
    else
      git config "lfs.https://github.com/${CANVA_REPO#*@github.com:}/info/lfs.access" basic
      git config "lfs.http://github.com/${CANVA_REPO#*@github.com:}/info/lfs.access" basic
    fi
  fi
  # make sure that the lfs hooks & filters are installed locally in the repo
  # in case they have not been installed in the S3 copy
  git lfs install --local --force
}

main() {
  SECONDS=0

  check_set CANVA_REPO
  check_set BUILDKITE_BRANCH
  check_set BUILDKITE_COMMIT
  check_set BUILDKITE_BUILD_CHECKOUT_PATH

  # shellcheck disable=SC2064
  trap exit_handler EXIT

  local git_lfs_skip_smudge_was_set=true
  (env | grep --quiet GIT_LFS_SKIP_SMUDGE=) || git_lfs_skip_smudge_was_set=false
  local old_git_lfs_skip_smudge="${GIT_LFS_SKIP_SMUDGE:-}"

  if ! command -v git-lfs >/dev/null; then
    export GIT_LFS_SKIP_SMUDGE=1
    echo >&2 "git-lfs not installed, skipping lfs"
  fi

  local max_retry=5
  local retry=0
  while true; do
    initialize_local_repo

    # set origin in case the repo was changed by the pre-checkout hook
    if [[ -v GITHUB_FETCH_APP_ACCESS_TOKEN ]]; then
      log_info "Setting origin to https://x-access-token:[[masked]]@github.com/${CANVA_REPO#*github.com/}"
    else
      log_info "Setting origin to ${CANVA_REPO}"
    fi

    git remote set-url origin "${CANVA_REPO}"

    if command -v git-lfs >/dev/null; then
      setup_git_lfs
    fi

    local exit_code
    exit_code=0
    checkout || exit_code=$?

    if [[ "${exit_code}" -eq 0 ]]; then
      log_info "main:Checkout successful."
      break
    fi

    log_info "main:Checkout failed with error code=${exit_code}. retry=${retry}"
    retry=$((retry + 1))

    if [[ "${retry}" -ge "${max_retry}" ]]; then
      log_info "main:Maximum retry reached."
      exit "${exit_code}"
    fi

  done

  if [[ "${git_lfs_skip_smudge_was_set}" == "true" ]]; then
    export GIT_LFS_SKIP_SMUDGE="${old_git_lfs_skip_smudge}"
  else
    unset GIT_LFS_SKIP_SMUDGE
  fi

  log_info "main:Update checkout success"
  buildkite-agent meta-data set "checkout_success" 0 --job "${BUILDKITE_JOB_ID}"

  local duration=$SECONDS

  echo "{\"event_type\":\"github-plugin-stats\",\"repo_initialisation_method\":\"${INITILISATION_METHOD}\",\"duration\":\"${duration}\",\"retry\":\"${retry}\"}"
  echo "{\"event_type\":\"github-plugin-stats\",\"repo_initialisation_method\":\"${INITILISATION_METHOD}\",\"duration\":\"${duration}\",\"retry\":\"${retry}\"}" | logger
  test $? -eq 0 || log_info "Fail to log statistics. Ignore error."

  # report checkout duration to datadog agent
  local repo_dir
  repo_dir=$(print_repo_dir)
  echo -n "github.checkout_time:${duration}|d|#repo:${repo_dir}" | nc -4u -w0 127.0.0.1 8125 || true
}

main "$@"
