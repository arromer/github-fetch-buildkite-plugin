#!/usr/bin/env bash

set -euo pipefail

# The maximum amount of time (in seconds) that a remote Git operation (fetch, pull, push) can take.
# If not specified by the user, no timeout will be applied to Git remote operations.
GIT_REMOTE_TIMEOUT="${BUILDKITE_PLUGIN_GITHUB_FETCH_GIT_REMOTE_TIMEOUT:-0}"

# Here is the exit code to be returned by this script when a remote Git operations times out.
# Having a specific exit code for these scenarions allows to configure Buildkite pipelines to retry
# the whole step without hiding underlying issues.
# See: https://buildkite.com/docs/pipelines/command-step#automatic-retry-attributes
#
# If not specified by the user, it defaults to 110 which is the standard exit code for connection timeout.
GIT_REMOTE_TIMEOUT_EXIT_CODE="${BUILDKITE_PLUGIN_GITHUB_FETCH_GIT_REMOTE_TIMEOUT_EXIT_CODE:-110}"

# Checks if an env var is set
# Arguments:
# $1: var name
check_set() {
  local name="$1"
  if [[ -z "${!name:-}" ]]; then
    echo "ERROR: ${name} not set"
    exit 1
  fi
}

# Checks for failed exit codes returned by a timeout command.
# If the underlying command fails due to timeout, this function stops the current execution returning either the
# TIMEOUT exit code (124) or the override value provided by the caller.
# In any other non-timeout failure scenarios, the current execution is stopped but the underlying command's exit
# code is returned unmodified.
# Arguments:
#   $1: The exit code returned by the timeout command.
#   $2: The exit code to be returned when the underlying command times out.
check_timeout_exit_code() {
  local exit_code="$1"
  local timeout_exit_code_override="${2:-}"
  if [[ "${exit_code}" -eq 124 && -n "${timeout_exit_code_override}" ]]; then
    exit "${timeout_exit_code_override}"
  elif [[ "${exit_code}" -ne 0 ]]; then
    exit "${exit_code}"
  fi
}

copy_checkout_from_s3() {
  local s3_url="$1"
  local checkout

  clean_checkout_dir

  # Find the most recent checkout in S3.
  checkout=$(aws s3 ls "${s3_url}/" \
      | (sort -r -k 4 || true) \
      | head -n1 \
      | awk '{print $4}'
  )

  pushd .. >/dev/null
  # shellcheck disable=SC2064
  trap "rm ${PWD}/${checkout}" EXIT
  aws s3 cp "${s3_url}/${checkout}" "${PWD}/${checkout}"
  tar -zxf "${PWD}/${checkout}"
  popd >/dev/null
}

checkout() {
  local exit_code
  git reset --hard
  git clean -ffxdq

  git config remote.origin.fetch

  if [[ -z "${BUILDKITE_COMMIT:-}" || "${BUILDKITE_COMMIT}" == "HEAD" ]]; then
    timeout "${GIT_REMOTE_TIMEOUT}" git fetch -v origin "${BUILDKITE_BRANCH}" ; exit_code=$?
    check_timeout_exit_code "${exit_code}" "${GIT_REMOTE_TIMEOUT_EXIT_CODE}"
    git checkout -f FETCH_HEAD
  elif git cat-file -e "${BUILDKITE_COMMIT}"; then
    git checkout -f "${BUILDKITE_COMMIT}"
  else
    timeout "${GIT_REMOTE_TIMEOUT}" git fetch -v origin "${BUILDKITE_COMMIT}" ; exit_code=$?
    check_timeout_exit_code "${exit_code}" "${GIT_REMOTE_TIMEOUT_EXIT_CODE}"
    # If the commit isn't there the ref that was pointing to it might have
    # been force pushed in the meantime. Exit with ESTALE to signify the stale
    # branch reference in that case.
    if [[ "${exit_code}" -eq 128 ]]; then
      exit 116
    # If checking out the commit fails, it might be because the commit isn't
    # being advertised. In that case fetch the branch instead.
    elif [[ "${exit_code}" -ne 0 ]]; then
      timeout "${GIT_REMOTE_TIMEOUT}" git fetch -v origin "${BUILDKITE_BRANCH}" ; exit_code=$?
      check_timeout_exit_code "${exit_code}" "${GIT_REMOTE_TIMEOUT_EXIT_CODE}"
      if [[ "${exit_code}" -ne 0 ]]; then
        exit "${exit_code}"
      fi
    fi
    # If the commit doesn't exist the ref that was pointing to it might have
    # been force pushed in the meantime. Exit with ESTALE to signify the stale
    # branch reference in that case.
    git checkout -f "${BUILDKITE_COMMIT}" ; exit_code=$?
    if [[ "${exit_code}" -eq 128 ]]; then
      exit 116
    elif [[ "${exit_code}" -ne 0 ]]; then
      exit "${exit_code}"
    fi
  fi
}

clean_checkout_dir() {
  rm -rf "${BUILDKITE_BUILD_CHECKOUT_PATH}"
  mkdir -p "${BUILDKITE_BUILD_CHECKOUT_PATH}"
  cd "${BUILDKITE_BUILD_CHECKOUT_PATH}"
}

clone() {
  local exit_code
  # The git clone operation needs an empty directory.
  clean_checkout_dir
  timeout "${GIT_REMOTE_TIMEOUT}" git clone "${BUILDKITE_REPO}" . ; exit_code=$?
  check_timeout_exit_code "${exit_code}" "${GIT_REMOTE_TIMEOUT_EXIT_CODE}"
}

setup_git_lfs() {
  if [[ "${BUILDKITE_REPO}" =~ .*github\.com.* ]]; then
    # Workaround for GitHub git-lfs API rate limit error:
    # https://github.com/git-lfs/git-lfs/issues/2133#issuecomment-292557138
    git config "lfs.https://github.com/${BUILDKITE_REPO#git@github.com:}/info/lfs.access" basic
  fi
}

main() {
  check_set BUILDKITE_REPO
  check_set BUILDKITE_BRANCH
  check_set BUILDKITE_COMMIT
  check_set BUILDKITE_BUILD_CHECKOUT_PATH

  local git_lfs_skip_smudge_was_set=true
  (env | grep --quiet GIT_LFS_SKIP_SMUDGE=) || git_lfs_skip_smudge_was_set=false
  local old_git_lfs_skip_smudge="${GIT_LFS_SKIP_SMUDGE:-}"

  if ! command -v git-lfs; then
    export GIT_LFS_SKIP_SMUDGE=1
    echo >&2 "git-lfs not installed, skipping lfs"
  fi
  # If the lock file exists it's probably because a previous job was killed while checking out the
  # repo, in which case it might be corrupted.
  if [[ "$(git rev-parse --is-inside-work-tree 2>/dev/null)" != "true" || -f ".git/index.lock" ]]; then
    if [[ -n "${BUILDKITE_PLUGIN_GITHUB_FETCH_S3_URL:-}" ]]; then
      copy_checkout_from_s3 "${BUILDKITE_PLUGIN_GITHUB_FETCH_S3_URL}"
    else
      clone
    fi
  fi
  if command -v git-lfs; then
    setup_git_lfs
  fi
  checkout

  if [[ "${git_lfs_skip_smudge_was_set}" == "true" ]]; then
    export GIT_LFS_SKIP_SMUDGE="${old_git_lfs_skip_smudge}"
  else
    unset GIT_LFS_SKIP_SMUDGE
  fi
}

main "$@"
