#!/usr/bin/env bash

set -euo pipefail

if [[ -n "${BUILDKITE_PLUGIN_GITHUB_FETCH_BASH_PREFIX:-}" ]]; then
  eval "${BUILDKITE_PLUGIN_GITHUB_FETCH_BASH_PREFIX}"
fi

# The maximum amount of time (in seconds) that a remote Git operation (fetch, pull, push) can take.
# If not specified by the user, no timeout will be applied to Git remote operations.
GIT_REMOTE_TIMEOUT="${BUILDKITE_PLUGIN_GITHUB_FETCH_GIT_REMOTE_TIMEOUT:-0}"

# Here is the exit code to be returned by this script when a remote Git operations times out.
# Having a specific exit code for these scenarions allows to configure Buildkite pipelines to retry
# the whole step without hiding underlying issues.
# See: https://buildkite.com/docs/pipelines/command-step#automatic-retry-attributes
#
# If not specified by the user, it defaults to 110 which is the standard exit code for connection timeout.
GIT_REMOTE_TIMEOUT_EXIT_CODE="${BUILDKITE_PLUGIN_GITHUB_FETCH_GIT_REMOTE_TIMEOUT_EXIT_CODE:-110}"

# Set to `true` forces a fresh clone from the remote to initialize the local copy for the first time
# on the agent.
#
# Otherwise it will re-use a cached copy from S3 for the first time or re-use the local repository.
BUILDKITE_CLEAN_CHECKOUT="${BUILDKITE_CLEAN_CHECKOUT:-false}"

# Prints an info line to stdout.
log_info() {
  echo "$(date '+[%Y-%m-%d %H:%M:%S]') INFO: $*"
}

# Checks if an env var is set
# Arguments:
# $1: var name
check_set() {
  local name="$1"
  if [[ -z "${!name:-}" ]]; then
    echo "ERROR: ${name} not set"
    exit 1
  fi
}

# Checks for failed exit codes returned by a timeout command.
# If the underlying command fails due to timeout, this function stops the current execution returning either the
# TIMEOUT exit code (124) or the override value provided by the caller.
# In any other non-timeout failure scenarios, the current execution is stopped but the underlying command's exit
# code is returned unmodified.
# Arguments:
#   $1: The exit code returned by the timeout command.
#   $2: The exit code to be returned when the underlying command times out.
check_timeout_exit_code() {
  local exit_code="$1"
  local timeout_exit_code_override="${2:-}"
  if [[ "${exit_code}" -eq 124 && -n "${timeout_exit_code_override}" ]]; then
    return "${timeout_exit_code_override}"
  elif [[ "${exit_code}" -ne 0 ]]; then
    return "${exit_code}"
  fi
}

copy_checkout_from_s3() {
  local s3_url="$1"
  local checkout

  log_info "Getting checkout from S3"

  clean_checkout_dir

  # Find the most recent checkout in S3.
  checkout=$(aws s3 ls "${s3_url}/" \
      | (sort -r -k 4 || true) \
      | head -n1 \
      | awk '{print $4}'
  )

  pushd .. >/dev/null
  # shellcheck disable=SC2064
  trap "rm ${PWD}/${checkout}" EXIT
  aws s3 cp "${s3_url}/${checkout}" "${PWD}/${checkout}"
  tar -zxf "${PWD}/${checkout}"
  popd >/dev/null

  log_info "Copying from S3 done"
}

checkout() {
  log_info "Starting checkout"

  local exit_code
  git reset --hard
  git clean -ffxdq

  # Check the current state to make sure we start from a clean working tree.
  # This does both "refresh the index and updating the cached stat information"
  # as per `man git-status` **BACKGROUND REFRESH**.
  git status

  git config remote.origin.fetch

  if [[ -z "${BUILDKITE_COMMIT:-}" || "${BUILDKITE_COMMIT}" == "HEAD" ]]; then
    exit_code=0
    timeout "${GIT_REMOTE_TIMEOUT}" git fetch -v --no-tags origin "${BUILDKITE_BRANCH}" || exit_code=$?
    check_timeout_exit_code "${exit_code}" "${GIT_REMOTE_TIMEOUT_EXIT_CODE}"
    GIT_TRACE=1 GIT_CURL_VERBOSE=1 git checkout -f FETCH_HEAD
  elif git cat-file -e "${BUILDKITE_COMMIT}"; then
    GIT_TRACE=1 GIT_CURL_VERBOSE=1 git checkout -f "${BUILDKITE_COMMIT}"
  else
    # full commit sha is required
    if [[ ! "${BUILDKITE_COMMIT}" =~ [0-9a-f]{40} ]]; then
      log_info "Commit SHA ${BUILDKITE_COMMIT} is not valid. Full SHA is required."
      exit 1
    fi
    exit_code=0
    timeout "${GIT_REMOTE_TIMEOUT}" git fetch -v --no-tags origin "${BUILDKITE_COMMIT}" || exit_code=$?
    check_timeout_exit_code "${exit_code}" "${GIT_REMOTE_TIMEOUT_EXIT_CODE}" || exit_code=$?
    # If the commit isn't there the ref that was pointing to it might have
    # been force pushed in the meantime. Exit with ESTALE to signify the stale
    # branch reference in that case.
    if [[ "${exit_code}" -eq 128 ]]; then
      exit 116
    # If checking out the commit fails, it might be because the commit isn't
    # being advertised. In that case fetch the branch instead.
    elif [[ "${exit_code}" -ne 0 ]]; then
      exit_code=0
      timeout "${GIT_REMOTE_TIMEOUT}" git fetch -v --no-tags origin "${BUILDKITE_BRANCH}" || exit_code=$?
      check_timeout_exit_code "${exit_code}" "${GIT_REMOTE_TIMEOUT_EXIT_CODE}"
    fi
    # If the commit doesn't exist the ref that was pointing to it might have
    # been force pushed in the meantime. Exit with ESTALE to signify the stale
    # branch reference in that case.
    exit_code=0
    GIT_TRACE=1 GIT_CURL_VERBOSE=1 git checkout -f "${BUILDKITE_COMMIT}" || exit_code=$?
    if [[ "${exit_code}" -eq 128 ]]; then
      exit 116
    elif [[ "${exit_code}" -ne 0 ]]; then
      exit "${exit_code}"
    fi
  fi
  log_info "Checkout done"
}

clean_checkout_dir() {
  rm -rf "${BUILDKITE_BUILD_CHECKOUT_PATH}"
  mkdir -p "${BUILDKITE_BUILD_CHECKOUT_PATH}"
  cd "${BUILDKITE_BUILD_CHECKOUT_PATH}"
}

clone() {
  log_info "Cloning repo from github"
  local exit_code
  # The git clone operation needs an empty directory.
  clean_checkout_dir
  exit_code=0
  timeout "${GIT_REMOTE_TIMEOUT}" git clone "${BUILDKITE_REPO}" . || exit_code=$?
  check_timeout_exit_code "${exit_code}" "${GIT_REMOTE_TIMEOUT_EXIT_CODE}"
  log_info "Cloning from github done"
}

initialize_local_repo() {
  # Force a fresh clone.
  if [[ "${BUILDKITE_CLEAN_CHECKOUT}" == "true" ]]; then
    clone
  # If there is no local repository or the index is in a locked state.
  # When the lock file exists it's probably because a previous job was killed while checking out the
  # repo, in which case it might be corrupted.
  elif [[ "$(git rev-parse --is-inside-work-tree 2>/dev/null)" != "true" || -f ".git/index.lock" ]]; then
    if [[ -n "${BUILDKITE_PLUGIN_GITHUB_FETCH_S3_URL:-}" ]]; then
      copy_checkout_from_s3 "${BUILDKITE_PLUGIN_GITHUB_FETCH_S3_URL}"
    else
      # When S3 was not configured, fallback to Git clone
      clone
    fi
  else
    log_info "Using existing local repository"
  fi
}

setup_git_lfs() {
  if [[ "${BUILDKITE_REPO}" =~ .*github\.com.* ]]; then
    # Workaround for GitHub git-lfs API rate limit error:
    # https://github.com/git-lfs/git-lfs/issues/2133#issuecomment-292557138
    git config "lfs.https://github.com/${BUILDKITE_REPO#*@github.com:}/info/lfs.access" basic
  fi
  # make sure that the lfs hooks & filters are installed locally in the repo
  # in case they have not been installed in the S3 copy
  git lfs install --local --force
}

main() {
  check_set BUILDKITE_REPO
  check_set BUILDKITE_BRANCH
  check_set BUILDKITE_COMMIT
  check_set BUILDKITE_BUILD_CHECKOUT_PATH

  local git_lfs_skip_smudge_was_set=true
  (env | grep --quiet GIT_LFS_SKIP_SMUDGE=) || git_lfs_skip_smudge_was_set=false
  local old_git_lfs_skip_smudge="${GIT_LFS_SKIP_SMUDGE:-}"

  if ! command -v git-lfs >/dev/null; then
    export GIT_LFS_SKIP_SMUDGE=1
    echo >&2 "git-lfs not installed, skipping lfs"
  fi

  initialize_local_repo

  # set origin in case the repo was changed by the pre-checkout hook
  log_info "Setting origin to ${BUILDKITE_REPO}"
  git remote set-url origin "${BUILDKITE_REPO}"

  if command -v git-lfs >/dev/null; then
    setup_git_lfs
  fi

  checkout

  if [[ "${git_lfs_skip_smudge_was_set}" == "true" ]]; then
    export GIT_LFS_SKIP_SMUDGE="${old_git_lfs_skip_smudge}"
  else
    unset GIT_LFS_SKIP_SMUDGE
  fi

  buildkite-agent meta-data set "checkout_success" 0 --job "${BUILDKITE_JOB_ID}"
}

main "$@"
